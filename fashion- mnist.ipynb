{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTING A BUNCH OF PYTORCH LIBRARIES \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns; sns.set()\n",
    "import copy, random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to Fashion-MNIST/FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Fashion-MNIST/FashionMNIST\\raw\\train-images-idx3-ubyte.gz to Fashion-MNIST/FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to Fashion-MNIST/FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Fashion-MNIST/FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to Fashion-MNIST/FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to Fashion-MNIST/FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Fashion-MNIST/FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to Fashion-MNIST/FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to Fashion-MNIST/FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Fashion-MNIST/FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to Fashion-MNIST/FashionMNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\torch\\csrc\\utils\\tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    }
   ],
   "source": [
    "trainset =   torchvision.datasets.FashionMNIST('Fashion-MNIST/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST('Fashion-MNIST/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader( testset, batch_size=4, shuffle=True)\n",
    "\n",
    "classes = ('0','1', '2', '3', '4','5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP DEFINITION\n",
    "\n",
    "### This network has 4 layers: \n",
    "### Input [784 x 1] --> Hidden-1 [300 x 1] --> Hidden-2 [100 x 1] --> Output [10 x 1]\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Fashion_MLP_MNIST(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Fashion_MLP_MNIST, self).__init__()\n",
    "        random_seed = 1;\n",
    "        torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(784,300),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(300,100),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100,10)\n",
    "            )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.fc(x);\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the weights and biases of the neural network. This is a Xavier initialization; \n",
    "# Optimal initialization of NN's is an entire field in itself :D \n",
    "\n",
    "def initialize_network(net):\n",
    "\n",
    "    random_seed = 1;\n",
    "    torch.manual_seed(random_seed)\n",
    "    for m in net.modules():\n",
    "        torch.manual_seed(random_seed)\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight);\n",
    "            nn.init.uniform_(m.bias);\n",
    "    \n",
    "    return net\n",
    "    '''\n",
    "    for name, param in autoenc_ch.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(name, param.data)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to evaluate the test accuracy of the network on test-data from MNIST\n",
    "\n",
    "def generalization_acc(net_mod):\n",
    "\n",
    "    correct = 0;\n",
    "    total = 0\n",
    "    batch_size = 4;\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.view(batch_size, -1)\n",
    "            outputs = net_mod(images);\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    #print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "    return (100 * correct / total);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to evaluate the train-accuracy of the network on the train-data from MNIST\n",
    "## (NOTE): There may be cases where the network has a very high train-accuracy but low test-accuracy --> commonly called overfitting\n",
    "\n",
    "def train_accuracy_Fashion_MNIST(net_mod):\n",
    "\n",
    "    correct = 0;\n",
    "    total = 0\n",
    "    batch_size = 4;\n",
    "    with torch.no_grad():\n",
    "        for data in trainloader:\n",
    "            images, labels = data\n",
    "            images = images.view(batch_size, -1)\n",
    "            outputs = net_mod(images);\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 60000 train images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    return (100 * correct / total);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining a Loss function for the neural network. \n",
    "# here, we use the cross-entropy loss. One can use L2 loss (any loss that is appropriate for the task at hand)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss();\n",
    "num_epochs = 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for training neural network \n",
    "\n",
    "def trainNetwork_Fashion_MNIST(net, wtsDict, num_epochs=2):\n",
    "\n",
    "    ## net: corresponds to the neural network that requires training\n",
    "    ## wtsDict: dictionary of weights, if you want to store the weights of intermediate networks while training (not reqd for conventional purposes)\n",
    "    ## num_epochs: number of epochs networks are to be trained for. One epoch is training the network on all train-datapoints in the batch\n",
    "    \n",
    "    \n",
    "    #storeWts_manifold2(net, wtsDict)\n",
    "    \n",
    "    ## Choosing an optimizer. Here, we choose Stochastic gradient descent (SGD) with learning rate=0.001 and momentum = 0.9\n",
    "    optimizer = optim.SGD(net.parameters(),lr=0.001, momentum=0.9)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        running_loss = 0.0;\n",
    "        batch_size = 4;\n",
    "\n",
    "        ctr_run = 0;\n",
    "        for i in range(0, 60000, batch_size):\n",
    "                \n",
    "            image_input = torch.empty(batch_size,784)\n",
    "            labels = torch.empty(batch_size);\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                img, label = trainset[i+j]\n",
    "                img = img[0,:,:];\n",
    "                img = img.view(1,784)\n",
    "        \n",
    "                image_input[j,:] = img;\n",
    "                labels[j] = label;\n",
    "\n",
    "            output = net(image_input);\n",
    "            loss = criterion(output, labels.long());\n",
    "\n",
    "            # =====================backward==================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            #plot_grad_flow(autoenc_ch.named_parameters)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if ctr_run % 2000 == 1999: # print every 8000 samples\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, ctr_run + 1, running_loss / 2000))\n",
    "                running_loss = 0.0;\n",
    "                #storeWts_manifold2(net, wtsDict); \n",
    "                #calcLoss_network.append(calculateLoss_network(net))\n",
    "                \n",
    "            ctr_run += 1;\n",
    "\n",
    "        acc = train_accuracy_Fashion_MNIST(net);\n",
    "        print(\"within func\")\n",
    "        \n",
    "        \n",
    "        ## I terminate training when accuracy reaches 98%; \n",
    "        ## One could train for a fixed number of epochs or until the network reaches a particular accuracy.\n",
    "        if num_epochs != 2:\n",
    "            # Evaluate if train accuracy is greater than 98%\n",
    "            if acc>98:\n",
    "                #storeWts_manifold2(net, wtsDict)\n",
    "                return (epoch+1, acc)\n",
    "        \n",
    "    return (epoch+1, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.769\n",
      "[1,  4000] loss: 0.515\n",
      "[1,  6000] loss: 0.473\n",
      "[1,  8000] loss: 0.431\n",
      "[1, 10000] loss: 0.425\n",
      "[1, 12000] loss: 0.412\n",
      "[1, 14000] loss: 0.408\n",
      "Accuracy of the network on the 60000 train images: 85 %\n",
      "within func\n",
      "[2,  2000] loss: 0.376\n",
      "[2,  4000] loss: 0.369\n",
      "[2,  6000] loss: 0.364\n",
      "[2,  8000] loss: 0.349\n",
      "[2, 10000] loss: 0.349\n",
      "[2, 12000] loss: 0.345\n",
      "[2, 14000] loss: 0.349\n",
      "Accuracy of the network on the 60000 train images: 87 %\n",
      "within func\n",
      "[3,  2000] loss: 0.324\n",
      "[3,  4000] loss: 0.323\n",
      "[3,  6000] loss: 0.321\n",
      "[3,  8000] loss: 0.310\n",
      "[3, 10000] loss: 0.310\n",
      "[3, 12000] loss: 0.309\n",
      "[3, 14000] loss: 0.314\n",
      "Accuracy of the network on the 60000 train images: 88 %\n",
      "within func\n",
      "[4,  2000] loss: 0.292\n",
      "[4,  4000] loss: 0.294\n",
      "[4,  6000] loss: 0.294\n",
      "[4,  8000] loss: 0.285\n",
      "[4, 10000] loss: 0.281\n",
      "[4, 12000] loss: 0.284\n",
      "[4, 14000] loss: 0.287\n",
      "Accuracy of the network on the 60000 train images: 89 %\n",
      "within func\n",
      "[5,  2000] loss: 0.270\n",
      "[5,  4000] loss: 0.273\n",
      "[5,  6000] loss: 0.273\n",
      "[5,  8000] loss: 0.263\n",
      "[5, 10000] loss: 0.259\n",
      "[5, 12000] loss: 0.263\n",
      "[5, 14000] loss: 0.268\n",
      "Accuracy of the network on the 60000 train images: 89 %\n",
      "within func\n"
     ]
    }
   ],
   "source": [
    "## Calling all the functions [to train the net]\n",
    "\n",
    "net_Fashion_MNIST = Fashion_MLP_MNIST();\n",
    "\n",
    "wtsDictionary_landscape = {};\n",
    "ctr = 1;\n",
    "for n,p in net_Fashion_MNIST.named_parameters():\n",
    "        \n",
    "    temp = list(p.view(1,-1).size());\n",
    "    wtsDictionary_landscape[ctr] = np.array([]).reshape(0,temp[1]);\n",
    "    ctr += 1\n",
    "    \n",
    "net_train = copy.deepcopy(net_Fashion_MNIST);\n",
    "[returnTime, acc] = trainNetwork_Fashion_MNIST(net_train, wtsDictionary_landscape, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
